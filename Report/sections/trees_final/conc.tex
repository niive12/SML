\subsection{Conclusion}
It can be found that the optimal preprossing of the data for decision trees is
smoothing, then
z-score, then
PCA with 130 chosen components,
Boosting with 7 trials, and removal of leaves with less than 7 digits.

G2M1
has been found to have the worst handwriting when comparing the data of all people.

