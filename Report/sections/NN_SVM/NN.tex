\subsection{Neural Networks}

Neural networks is a model based on biology. 
Initially all neurons are connected. 
When the connection is active the synapses becomes stronger and when the connection is inactive the synapses becomes weaker.

The Stuttgart Neural Network Simulator is implemented in R in the RSNNS package.
The package can make a model of a artificial neural network (ANN) as a multi-layered perceptron.
To reduce the inputs the data is normalized using the Z-Score method and a principle components analysis is made to give the most important data points.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{graphics/neural_network_visualized}
    \caption[Visualization of a ANN model.]{Visualization of a ANN model with 5 PC and 10 hidden layers. Plotted using \url{https://github.com/fawda123/NeuralNetTools}}
    \label{fig:neural_network_visualised}
\end{figure}

In the following section will the relationship with number of PC and the number of hidden layers be explored.
In figure \ref{fig:neural_network_visualised} is a small ANS shown.
The thickness of the synapses indicates the weight.
The black color indicates a positive weight and the grey color indicates a negative weights.
It is important to notice that there is only a single output. 
Testing a digit will only show if the entered number resembles the train data or not.
In order to distinguish between multiple classes a model for each class is created.
Then the class with the highest resemblance is chosen.
The data is separated so it becomes 1 when the class matches and 0 when it doesn't.
To determine the class of a test digit each model is tested as shown in code segment \ref{code:nn_separation}.

\lstinputlisting[language = R,
firstnumber = 36,
firstline = 36, 
lastline = 40, 
captionpos=b,
caption = {NN detection.},
label = {code:nn_separation}]{../Code/KNN/01/neural_network_simplified.R}

To investigate the relation between the number of PC and hidden layers both parameters were tested against each other in figure \ref{fig:contour_nn_size_vs_pca}. 
The problem tested is taking train data from all students and excluding the test person. 
From that it can be concluded that there is a sweet spot in the number of PC where the number of hidden layers is larger than the number of inputs.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{graphics/contour_nn_size_vs_pca}
    \caption[Success of ANN, PC vs HL]{Success of ANN when tested on G3M2 against everyone else's data.}
    \label{fig:contour_nn_size_vs_pca}
\end{figure}

The timing was measured in figure \ref{fig:contour_nn_both}.
The timing was split up into making the model and predicting the class.
The time it took to create the 10 models is shown in figure \ref{fig:contour_nn_size_vs_pca_time_model}.
% The time it took to predict all 4000 data points is shown in figure \ref{fig:contour_nn_size_vs_pca_time_predict}.
The biggest impact comes from number PC when building the model but the relationship is more linear when it comes to predicting.

\begin{figure}[h]
    \begin{subfigure}{0.49\textwidth}
    \centering
        \includegraphics[width=\textwidth]{graphics/contour_nn_size_vs_pca_model}
        \caption{Time to build a ANN}
        \label{fig:contour_nn_size_vs_pca_time_model}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \includegraphics[width=\textwidth]{graphics/contour_nn_size_vs_pca_predict}
        \caption{Time of predicting using ANN}
        \label{fig:contour_nn_size_vs_pca_time_predict}
    \end{subfigure}
    \caption{Timing tested on G3M2 against everyone's data. The time is measured in seconds.}
    \label{fig:contour_nn_both}
\end{figure}

To view the impact of the train data size the timing and success was measured with a varying train set size.
The test is G3M2 tested against the rest of the students.
The data was normalized and the first 200 PC was used.
In all tests were 200 hidden layers in the ANN.
The Train size / digit refers to the number of samples per digit per person.
In figure \ref{fig:nn_timing_trainsize} is the timing and success plottet.
As expected is it shown that decreasing the train data will decrease the time it takes to build the model.
It is also shown that using more training digits does not increase the performance and thus this is a viable option.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{graphics/nn_timing_trainsize_200}
    \caption{Timing of building a ANN}
    \label{fig:nn_timing_trainsize}
\end{figure}
